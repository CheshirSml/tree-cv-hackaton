"""
–ü–û–õ–ù–´–ô –°–¶–ï–ù–ê–†–ò–ô –ò–ù–§–ï–†–ï–ù–°–ê: YOLOv10-seg + –≤—ã–±–æ—Ä –≥–ª–∞–≤–Ω–æ–≥–æ —Å—Ç–≤–æ–ª–∞ + EfficientNet-B0

–¶–µ–ª—å: 
  –ü–æ –≤—Ö–æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –ª–µ—Å–∞/–ø–∞—Ä–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ—Ä–æ–¥—É –≥–ª–∞–≤–Ω–æ–≥–æ –¥–µ—Ä–µ–≤–∞ –∏ –≤–µ—Ä–Ω—É—Ç—å:
    - –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å bbox –≥–ª–∞–≤–Ω–æ–≥–æ —Å—Ç–≤–æ–ª–∞,
    - –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–æ—Ä–æ–¥—ã –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏,
    - –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ Gemini 2.5 Flash.

–≠—Ç–∞–ø—ã –ø–∞–π–ø–ª–∞–π–Ω–∞ (—Å–æ–≥–ª–∞—Å–Ω–æ –∑–∞–¥–∞–Ω–∏—é):
1.0. YOLOv10-seg –¥–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç –∏ —Å–µ–≥–º–µ–Ω—Ç–∏—Ä—É–µ—Ç –≤—Å–µ —Å—Ç–≤–æ–ª—ã.
2.0. –í—ã–±–∏—Ä–∞–µ—Ç—Å—è "–≥–ª–∞–≤–Ω—ã–π" —Å—Ç–≤–æ–ª –ø–æ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É –∫—Ä–∏—Ç–µ—Ä–∏—é (—Ä–∞–∑–º–µ—Ä + —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç—å).
3.0. –ü–æ –º–∞—Å–∫–µ –≥–ª–∞–≤–Ω–æ–≥–æ —Å—Ç–≤–æ–ª–∞ –∏–∑–≤–ª–µ–∫–∞–µ—Ç—Å—è ROI (Region of Interest) ‚Äî –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–æ—Ä—ã –±–µ–∑ —Ñ–æ–Ω–∞.
4.0. EfficientNet-B0 –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç ROI –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–æ—Ä–æ–¥—É.
5.1. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –∫—Ä–∞—Å–Ω—ã–º bbox –≤–æ–∫—Ä—É–≥ –≥–ª–∞–≤–Ω–æ–≥–æ —Å—Ç–≤–æ–ª–∞.
5.2. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç EfficientNet-B0: –ø–æ—Ä–æ–¥–∞ + —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (–¥–ª—è Gemini).
5.3. –í–æ–∑–≤—Ä–∞—â–∞—é—Ç—Å—è –≤—Å–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (bbox, ROI, –º–∞—Å–∫–∞ –∏ —Ç.–¥.) ‚Äî –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –æ—Ç–ª–∞–¥–∫–∏.
"""

# –ò–º–ø–æ—Ä—Ç—ã —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
import os
import math
import cv2
import numpy as np
from pathlib import Path

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π
from PIL import Image, ImageDraw

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è –º–æ–¥–µ–ª–µ–π –∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
import torch
import torch.nn as nn
from torchvision import transforms
from ultralytics import YOLO


# ==============================================================================
# 1. –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# ==============================================================================

def select_primary_object(boxes, image_size):
    """
    –≠—Ç–∞–ø 2.0: –í—ã–±–æ—Ä –≥–ª–∞–≤–Ω–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ –∏–∑ —Å–ø–∏—Å–∫–∞ bounding boxes.
    
    –õ–æ–≥–∏–∫–∞ –≤—ã–±–æ—Ä–∞:
      - –ß–µ–º –±–æ–ª—å—à–µ –ø–ª–æ—â–∞–¥—å bbox ‚Äî —Ç–µ–º –≤—ã—à–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç (—Å—Ç–≤–æ–ª –∫—Ä—É–ø–Ω–µ–µ ‚Üí –±–ª–∏–∂–µ/–≤–∞–∂–Ω–µ–µ).
      - –ß–µ–º –±–ª–∏–∂–µ —Ü–µ–Ω—Ç—Ä bbox –∫ —Ü–µ–Ω—Ç—Ä—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ‚Äî —Ç–µ–º –≤—ã—à–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç (—Ñ–æ–∫—É—Å —Å—ä—ë–º–∫–∏).
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã bbox –≥–ª–∞–≤–Ω–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ [x1, y1, x2, y2] –∏–ª–∏ None.
    """
    if not boxes:
        return None

    W, H = image_size
    max_dist = math.sqrt((W / 2) ** 2 + (H / 2) ** 2)  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ —É–≥–ª–∞
    best_box, best_score = None, -1

    for bbox in boxes:
        x1, y1, x2, y2 = bbox
        area = (x2 - x1) * (y2 - y1)
        norm_area = area / (W * H + 1e-6)  # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–æ –ø–ª–æ—â–∞–¥–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è

        box_cx, box_cy = (x1 + x2) / 2, (y1 + y2) / 2
        dist = math.sqrt((box_cx - W / 2) ** 2 + (box_cy - H / 2) ** 2)
        norm_dist = 1 - (dist / (max_dist + 1e-6))  # 1 = –≤ —Ü–µ–Ω—Ç—Ä–µ, 0 = –≤ —É–≥–ª—É

        # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∫–æ—Ä: 60% ‚Äî —Ä–∞–∑–º–µ—Ä, 40% ‚Äî —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç—å
        score = 0.6 * norm_area + 0.4 * norm_dist

        if score > best_score:
            best_score = score
            best_box = bbox

    return best_box


def extract_roi_from_mask(image, mask, output_size=(224, 224)):
    """
    –≠—Ç–∞–ø 3.0: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ ROI –ø–æ –±–∏–Ω–∞—Ä–Ω–æ–π –º–∞—Å–∫–µ.
    
    –ß—Ç–æ –¥–µ–ª–∞–µ—Ç:
      - –ù–∞—Ö–æ–¥–∏—Ç bounding box –º–∞—Å–∫–∏,
      - –û–±—Ä–µ–∑–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ —ç—Ç–æ–º—É bbox,
      - –ü—Ä–∏–º–µ–Ω—è–µ—Ç –º–∞—Å–∫—É: –≤—Å—ë, —á—Ç–æ –≤–Ω–µ —Å—Ç–≤–æ–ª–∞ ‚Äî —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è —á—ë—Ä–Ω—ã–º (—Ñ–æ–Ω —É–±–∏—Ä–∞–µ—Ç—Å—è),
      - –†–µ—Å–∞–π–∑–∏—Ç –¥–æ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ (224√ó224), –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ –¥–ª—è EfficientNet-B0.
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: numpy-–º–∞—Å—Å–∏–≤ (H, W, 3) –≤ —Ñ–æ—Ä–º–∞—Ç–µ BGR –∏–ª–∏ None, –µ—Å–ª–∏ –º–∞—Å–∫–∞ –ø—É—Å—Ç–∞—è.
    """
    # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –º–∞—Å–∫–∞ ‚Äî –±—É–ª–µ–≤–∞ (–≤–∞–∂–Ω–æ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å float-–º–∞—Å–∫–∞–º–∏ –æ—Ç YOLO)
    if mask.dtype != bool:
        mask = mask > 0.5

    # –ù–∞–π–¥—ë–º –Ω–µ–Ω—É–ª–µ–≤—ã–µ –ø–∏–∫—Å–µ–ª–∏
    coords = np.column_stack(np.where(mask))
    if coords.size == 0:
        return None

    # –û–ø—Ä–µ–¥–µ–ª–∏–º bbox –ø–æ –º–∞—Å–∫–µ
    y_min, x_min = coords.min(axis=0)
    y_max, x_max = coords.max(axis=0)

    # –û–±—Ä–µ–∂–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –º–∞—Å–∫—É
    roi_img = image[y_min:y_max+1, x_min:x_max+1]
    roi_mask = mask[y_min:y_max+1, x_min:x_max+1]

    # –ü—Ä–∏–º–µ–Ω–∏–º –º–∞—Å–∫—É: —Ñ–æ–Ω ‚Üí —á—ë—Ä–Ω—ã–π
    roi_masked = roi_img.copy()
    roi_masked[~roi_mask] = 0

    # –ü—Ä–∏–≤–µ–¥—ë–º –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É —Ä–∞–∑–º–µ—Ä—É –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
    return cv2.resize(roi_masked, output_size, interpolation=cv2.INTER_LINEAR)


def create_efficientnet_model(num_classes):
    """
    –°–æ–∑–¥–∞—ë—Ç –º–æ–¥–µ–ª—å EfficientNet-B0 —Å –∏–∑–º–µ–Ω—ë–Ω–Ω–æ–π –≥–æ–ª–æ–≤–æ–π –ø–æ–¥ –∑–∞–¥–∞–Ω–Ω–æ–µ —á–∏—Å–ª–æ –∫–ª–∞—Å—Å–æ–≤.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –Ω–∞ —ç—Ç–∞–ø–µ 4.0.
    """
    from torchvision.models import efficientnet_b0
    model = efficientnet_b0(weights=None)  # –≤–µ—Å–∞ –∑–∞–≥—Ä—É–∑–∏–º –ø–æ–∑–∂–µ –∏–∑ —á–µ–∫–ø–æ–∏–Ω—Ç–∞
    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)
    return model


def predict_breed_from_roi(roi_image, model_path):
    """
    –≠—Ç–∞–ø 4.0: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ—Ä–æ–¥—ã –ø–æ ROI.
    
    –í—Ö–æ–¥: 
      - roi_image: numpy-–º–∞—Å—Å–∏–≤ (BGR, H, W, 3),
      - model_path: –ø—É—Ç—å –∫ —á–µ–∫–ø–æ–∏–Ω—Ç—É EfficientNet-B0 (–±–µ–∑ LabelEncoder!).
    
    –í—ã—Ö–æ–¥: (–ø–æ—Ä–æ–¥–∞: str, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: float)
    """
    device = "cuda" if torch.cuda.is_available() else "cpu"

    # –ó–∞–≥—Ä—É–∑–∫–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–∞ (–±–µ–∑–æ–ø–∞—Å–Ω–æ, weights_only=True)
    checkpoint = torch.load(model_path, map_location=device, weights_only=True)
    classes = checkpoint['classes']  # —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫: ['–±–µ—Ä—ë–∑–∞', '–¥—É–±', ...]
    num_classes = len(classes)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏
    model = create_efficientnet_model(num_classes)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    model.eval()

    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ ROI –≤ —Ñ–æ—Ä–º–∞—Ç, –æ–∂–∏–¥–∞–µ–º—ã–π EfficientNet
    roi_rgb = cv2.cvtColor(roi_image, cv2.COLOR_BGR2RGB)
    pil_img = Image.fromarray(roi_rgb)
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet
    ])
    img_tensor = transform(pil_img).unsqueeze(0).to(device)

    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    with torch.no_grad():
        output = model(img_tensor)
        probs = torch.softmax(output, dim=1)  # –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø–æ –∫–ª–∞—Å—Å–∞–º
        confidence, idx = torch.max(probs, dim=1)
        breed = classes[idx.item()]

    return breed, confidence.item()


# ==============================================================================
# 2. –û–°–ù–û–í–ù–û–ô –ü–ê–ô–ü–õ–ê–ô–ù –ò–ù–§–ï–†–ï–ù–°–ê
# ==============================================================================

def run_inference_pipeline(
    image_path: str,
    yolo_model_path: str,
    efficientnet_model_path: str,
    output_dir: str = "inference_output",
    conf_threshold: float = 0.5
):
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è, —Ä–µ–∞–ª–∏–∑—É—é—â–∞—è –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (—ç—Ç–∞–ø—ã 1.0‚Äì5.3).
    
    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
      - image_path: –ø—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é (.jpg, .png),
      - yolo_model_path: –ø—É—Ç—å –∫ –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π YOLOv10-seg –º–æ–¥–µ–ª–∏,
      - efficientnet_model_path: –ø—É—Ç—å –∫ —á–µ–∫–ø–æ–∏–Ω—Ç—É EfficientNet-B0,
      - output_dir: –ø–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤,
      - conf_threshold: –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ YOLO (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.5).
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: —Å–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ (—Å–º. —ç—Ç–∞–ø—ã 5.1‚Äì5.3).
    """
    # –°–æ–∑–¥–∞—ë–º –≤—ã—Ö–æ–¥–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
    os.makedirs(output_dir, exist_ok=True)
    image_path = Path(image_path)
    base_name = image_path.stem

    # --- –≠—Ç–∞–ø 1.0: –ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ---
    orig_cv_img = cv2.imread(str(image_path))
    if orig_cv_img is None:
        raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}")
    h, w = orig_cv_img.shape[:2]

    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ PIL –¥–ª—è —É–¥–æ–±–Ω–æ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
    pil_img = Image.fromarray(cv2.cvtColor(orig_cv_img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(pil_img)

    # --- –≠—Ç–∞–ø 1.0: –ó–∞–ø—É—Å–∫ YOLOv10-seg ---
    yolo_model = YOLO(yolo_model_path)
    results = yolo_model(pil_img, verbose=False)

    all_boxes = []
    all_masks = []

    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å–æ —Å—Ç–µ–ø–µ–Ω—å—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ ‚â• conf_threshold
    for result in results:
        if result.boxes is None or result.masks is None:
            continue
        for box, mask in zip(result.boxes, result.masks):
            if box.conf >= conf_threshold:
                bbox = box.xyxy[0].cpu().numpy().tolist()
                mask_np = mask.data[0].cpu().numpy()
                # –ú–∞—Å–∫–∞ –æ—Ç YOLO ‚Äî –º–∞–ª–µ–Ω—å–∫–∞—è; —Ä–µ—Å–∞–π–∑–∏–º –¥–æ —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                mask_full = cv2.resize(mask_np, (w, h), interpolation=cv2.INTER_NEAREST)
                all_boxes.append(bbox)
                all_masks.append(mask_full)

                # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: —Ä–∏—Å—É–µ–º –≤—Å–µ bbox (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
                x1, y1, x2, y2 = map(int, bbox)
                draw.rectangle([x1, y1, x2, y2], outline="blue", width=2)

    if not all_boxes:
        return {"error": "no_trunks_detected"}

    # --- –≠—Ç–∞–ø 2.0: –í—ã–±–æ—Ä –≥–ª–∞–≤–Ω–æ–≥–æ —Å—Ç–≤–æ–ª–∞ ---
    primary_bbox = select_primary_object(all_boxes, (w, h))
    if primary_bbox is None:
        return {"error": "no_primary_selected"}

    # --- –≠—Ç–∞–ø 2.0 ‚Üí 3.0: –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –º–∞—Å–∫–∏ –≥–ª–∞–≤–Ω–æ–º—É bbox —á–µ—Ä–µ–∑ IoU ---
    # –°–æ–∑–¥–∞—ë–º –±–∏–Ω–∞—Ä–Ω—É—é –º–∞—Å–∫—É bbox (–¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è)
    x1_p, y1_p, x2_p, y2_p = primary_bbox
    primary_box_mask = np.zeros((h, w), dtype=bool)
    primary_box_mask[int(y1_p):int(y2_p), int(x1_p):int(x2_p)] = True

    # –ù–∞—Ö–æ–¥–∏–º –º–∞—Å–∫—É –æ—Ç YOLO, –∫–æ—Ç–æ—Ä–∞—è –ª—É—á—à–µ –≤—Å–µ–≥–æ –ø–µ—Ä–µ—Å–µ–∫–∞–µ—Ç—Å—è —Å bbox
    primary_mask = None
    best_iou = 0
    for mask in all_masks:
        mask_bool = mask > 0.5  # –ø—Ä–∏–≤–æ–¥–∏–º float-–º–∞—Å–∫—É –∫ bool
        intersection = np.logical_and(mask_bool, primary_box_mask)
        union = np.logical_or(mask_bool, primary_box_mask)
        iou = np.sum(intersection) / (np.sum(union) + 1e-6)
        if iou > best_iou:
            best_iou = iou
            primary_mask = mask  # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –º–∞—Å–∫—É –¥–ª—è ROI

    if primary_mask is None:
        primary_mask = all_masks[0]  # fallback

    # –†–∏—Å—É–µ–º bbox –≥–ª–∞–≤–Ω–æ–≥–æ —Å—Ç–≤–æ–ª–∞ –∫—Ä–∞—Å–Ω—ã–º (—ç—Ç–∞–ø 5.1)
    x1, y1, x2, y2 = map(int, primary_bbox)
    draw.rectangle([x1, y1, x2, y2], outline="red", width=3)

    # --- –≠—Ç–∞–ø 3.0: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ ROI –ø–æ –º–∞—Å–∫–µ ---
    roi_image = extract_roi_from_mask(orig_cv_img, primary_mask > 0.5, output_size=(224, 224))
    if roi_image is None:
        return {"error": "roi_extraction_failed"}

    # --- –≠—Ç–∞–ø 4.0: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ—Ä–æ–¥—ã ---
    breed, confidence = predict_breed_from_roi(roi_image, efficientnet_model_path)

    # --- –≠—Ç–∞–ø—ã 5.1‚Äì5.3: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –≤–æ–∑–≤—Ä–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ---
    annotated_path = Path(output_dir) / f"{base_name}_annotated.jpg"
    roi_path = Path(output_dir) / f"{base_name}_roi.jpg"

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (5.1)
    annotated_img_bgr = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
    cv2.imwrite(str(annotated_path), annotated_img_bgr)
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º ROI (5.3)
    cv2.imwrite(str(roi_path), roi_image)

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö (5.1, 5.2, 5.3)
    return {
        # 5.1: –í–∏–∑—É–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        "annotated_image_path": str(annotated_path),
        # 5.2: –†–µ–∑—É–ª—å—Ç–∞—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–¥–ª—è Gemini)
        "breed": breed,
        "confidence": confidence,
        # 5.3: –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        "roi_image_path": str(roi_path),
        "primary_bbox": primary_bbox,          # –º–æ–∂–Ω–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≤ Gemini –≤–º–µ—Å—Ç–æ ROI
        "primary_roi_path": str(roi_path),     # –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å ROI
        "total_detections": len(all_boxes),
        "primary_mask": primary_mask           # –ø–æ–ª–Ω–∞—è –º–∞—Å–∫–∞ (–º–æ–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–∞–∫ .npy)
    }


# ==============================================================================
# 3. –¢–û–ß–ö–ê –í–•–û–î–ê (–ö–û–ú–ê–ù–î–ù–ê–Ø –°–¢–†–û–ö–ê)
# ==============================================================================

if __name__ == "__main__":
    import argparse

    # –ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    parser = argparse.ArgumentParser(
        description="–ò–Ω—Ñ–µ—Ä–µ–Ω—Å –ø–∞–π–ø–ª–∞–π–Ω: YOLOv10-seg + EfficientNet-B0 –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ—Ä–æ–¥—ã –¥–µ—Ä–µ–≤–∞"
    )
    parser.add_argument("image", type=str, help="–ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é")
    parser.add_argument("--yolo", type=str, default="yolov10s-seg.pt", help="–ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ YOLOv10-seg")
    parser.add_argument("--efficientnet", type=str, default="best_efficientnet_b0_breed_safe.pth", help="–ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ EfficientNet-B0")
    parser.add_argument("--output", type=str, default="inference_output", help="–ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

    args = parser.parse_args()

    # –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞
    try:
        result = run_inference_pipeline(
            image_path=args.image,
            yolo_model_path=args.yolo,
            efficientnet_model_path=args.efficientnet,
            output_dir=args.output
        )

        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ –∫–æ–Ω—Å–æ–ª—å
        if "error" in result:
            print(f"‚ùå –û—à–∏–±–∫–∞: {result['error']}")
        else:
            print("‚úÖ –ò–Ω—Ñ–µ—Ä–µ–Ω—Å –∑–∞–≤–µ—Ä—à—ë–Ω —É—Å–ø–µ—à–Ω–æ!")
            print(f"  üå≥ –ü–æ—Ä–æ–¥–∞: {result['breed']}")
            print(f"  üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence']:.4f}")
            print(f"  üñºÔ∏è –ê–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {result['annotated_image_path']}")
            print(f"  üß¨ ROI: {result['roi_image_path']}")
            print(f"  üì¶ BBox –≥–ª–∞–≤–Ω–æ–≥–æ —Å—Ç–≤–æ–ª–∞: {result['primary_bbox']}")
            print(f"  üî¢ –í—Å–µ–≥–æ —Å—Ç–≤–æ–ª–æ–≤: {result['total_detections']}")

    except Exception as e:
        print(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")